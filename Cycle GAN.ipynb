{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "config = edict()\n",
    "config.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "config.TRAIN_DIR = \"data/train\"\n",
    "config.VAL_DIR = \"data/val\"\n",
    "config.BATCH_SIZE = 1\n",
    "config.LEARNING_RATE = 1e-5\n",
    "config.LAMBDA_IDENTITY = 0.0\n",
    "config.LAMBDA_CYCLE = 10\n",
    "config.NUM_WORKERS = 0\n",
    "config.NUM_EPOCHS = 10\n",
    "config.LOAD_MODEL = False\n",
    "config.SAVE_MODEL = True\n",
    "config.CHECKPOINT_GEN_H = \"genh.pth.tar\"\n",
    "config.CHECKPOINT_GEN_Z = \"genz.pth.tar\"\n",
    "config.CHECKPOINT_CRITIC_H = \"critich.pth.tar\"\n",
    "config.CHECKPOINT_CRITIC_Z = \"criticz.pth.tar\"\n",
    "\n",
    "config.transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(width=256, height=256),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
    "        ToTensorV2(),\n",
    "     ],\n",
    "    additional_targets={\"image0\": \"image\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels = 3, features = [64, 128, 256, 512]):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,features[0], 4, 2, 1, padding_mode = 'reflect'),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "        \n",
    "        )\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        in_channels = features[0]\n",
    "        \n",
    "        for out_channels in features[1:]:\n",
    "            layer = self.block(in_channels, out_channels , 1 if out_channels==features[-1] else 2)\n",
    "            layers.append(layer)\n",
    "            in_channels = out_channels \n",
    "            \n",
    "        layer = nn.Conv2d(in_channels, 1, 4, 1,1, padding_mode = 'reflect')\n",
    "        layers.append(layer)\n",
    "            \n",
    "            \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        \n",
    "    def block(self, in_channels, out_channels, stride):\n",
    "        conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size = 4, stride = stride, padding = 1, bias = True, padding_mode = 'reflect'),\n",
    "            nn.InstanceNorm2d(out_channels), \n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "        )\n",
    "        return conv \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        return torch.sigmoid(self.model(x))\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((5, 3, 256, 256))\n",
    "model = Discriminator()\n",
    "preds = model(x)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (initial): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
       "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
       "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (3): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            self.convBlock(channels, channels, kernel_size=3, padding = 1),\n",
    "            self.convBlock(channels, channels, kernel_size = 3, padding = 1),\n",
    "        \n",
    "        )\n",
    "        \n",
    "        \n",
    "    def convBlock(self, in_channels, out_channels,down = True, use_act = True, **kwargs):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, **kwargs, padding_mode = 'reflect')\n",
    "            if down \n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace = True) if use_act else nn.Identity()\n",
    "            \n",
    "        )\n",
    "        \n",
    "        return block \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x+ self.block(x)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,img_channels=3, num_features = 64, num_residuals = 9):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, num_features, 7, 1, padding = 3, padding_mode = 'reflect'),\n",
    "            nn.InstanceNorm2d(num_features),\n",
    "            nn.ReLU(inplace = True),\n",
    "        )\n",
    "        \n",
    "        self.down_blocks = nn.ModuleList(\n",
    "            [\n",
    "                self.convBlock(num_features, num_features*2, kernel_size = 3, stride = 2, padding =1),\n",
    "                self.convBlock(num_features*2, num_features*4, kernel_size = 3, stride = 2, padding =1)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.transformer_block = nn.Sequential(\n",
    "            *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.up_blocks = nn.ModuleList(\n",
    "            [\n",
    "                self.convBlock(num_features*4, num_features*2, down = False, kernel_size = 3, stride =2, padding = 1, output_padding = 1),\n",
    "                self.convBlock(num_features*2, num_features, down = False, kernel_size = 3, stride = 2, padding = 1, output_padding = 1)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.last = nn.Conv2d(num_features, img_channels, kernel_size = 7, stride = 1, padding = 3, padding_mode = 'reflect')\n",
    "        \n",
    "        \n",
    "    def convBlock(self, in_channels, out_channels,down = True, use_act = True, **kwargs):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, **kwargs, padding_mode = 'reflect')\n",
    "            if down \n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace = True) if use_act else nn.Identity()\n",
    "            \n",
    "        )\n",
    "        \n",
    "        return block \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        for layer in self.down_blocks:\n",
    "            x = layer(x)\n",
    "            \n",
    "        x = self.transformer_block(x)\n",
    "        \n",
    "        for layer in self.up_blocks:\n",
    "            x = layer(x)\n",
    "            \n",
    "        return torch.tanh(self.last((x)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    img_channels = 3\n",
    "    img_size = 256\n",
    "    x = torch.randn((2, img_channels, img_size, img_size))\n",
    "    gen = Generator(img_channels, 9)\n",
    "    print(gen(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import os \n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorseZebraDataset(Dataset):\n",
    "    def __init__(self, root_zebra, root_horse, transform = None):\n",
    "        self.root_zebra = root_zebra \n",
    "        self.root_horse = root_horse\n",
    "        self.transform = transform \n",
    "        \n",
    "        self.zebra_images = os.listdir(root_zebra)\n",
    "        self.horse_images = os.listdir(root_horse)\n",
    "        self.length_dataset = max(len(self.zebra_images), len(self.horse_images)) # 1000, 1500\n",
    "        self.zebra_len = len(self.zebra_images)\n",
    "        self.horse_len = len(self.horse_images)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length_dataset \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        zebra_img = self.zebra_images[index % self.zebra_len]\n",
    "        horse_img = self.horse_images[index % self.horse_len]\n",
    "        \n",
    "        zebra_path = os.path.join(self.root_zebra, zebra_img)\n",
    "        horse_path = os.path.join(self.root_horse, horse_img)\n",
    "        \n",
    "        zebra_image = np.array(Image.open(zebra_path).convert(\"RGB\"))\n",
    "        horse_image = np.array(Image.open(horse_path).convert(\"RGB\"))\n",
    "        \n",
    "        if self.transform: \n",
    "            augmentations = self.transform(image= zebra_image, image0 = horse_image)\n",
    "            zebra_image = augmentations[\"image\"]\n",
    "            horse_image = augmentations[\"image0\"]\n",
    "            \n",
    "        return zebra_image, horse_image \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch , random, os, numpy as np \n",
    "import torch.nn as nn\n",
    "#import config\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, filename = 'mycheckpoint.pth.tar'):\n",
    "    print( \"=> Saving Checkpoint\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    \n",
    "    torch.save(checkpoint, filename)\n",
    "    \n",
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location = config.DEVICE)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    \n",
    "    \n",
    "    for param_group in optimizer.param_groups: \n",
    "        param_group[\"lr\"] = lr\n",
    "        \n",
    "\n",
    "def seed_everything(seed = 42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim \n",
    "from tqdm import tqdm \n",
    "from torchvision.utils import save_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler):\n",
    "    H_reals = 0\n",
    "    H_fakes = 0 \n",
    "    \n",
    "    loop = tqdm(loader, leave = True)\n",
    "    \n",
    "    for idx, (zebra, horse) in enumerate(loop):\n",
    "        zebra = zebra.to(config.DEVICE)\n",
    "        horse = horse.to(config.DEVICE)\n",
    "        \n",
    "        # train discrimininator H and Z \n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            fake_horse = gen_H(zebra) \n",
    "            \n",
    "            D_H_real = disc_H(horse)\n",
    "            D_H_fake = disc_H(fake_horse.detach())\n",
    "            \n",
    "            H_reals += D_H_real.mean().item()\n",
    "            H_fakes += D_H_fake.mean().item()\n",
    "            \n",
    "            D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n",
    "            D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n",
    "            \n",
    "            D_H_loss = D_H_real_loss + D_H_fake_loss\n",
    "\n",
    "            \n",
    "            \n",
    "            # for zebra generator \n",
    "            fake_zebra = gen_Z(horse) \n",
    "            D_Z_real = disc_Z(zebra)\n",
    "            D_Z_fake = disc_Z(fake_zebra.detach())\n",
    "            \n",
    "            D_Z_real_loss = mse(D_Z_real, torch.ones_like(D_Z_real))\n",
    "            D_Z_fake_loss = mse(D_Z_fake, torch.ones_like(D_Z_fake))\n",
    "            \n",
    "            D_Z_loss = D_Z_real_loss + D_Z_fake_loss \n",
    "            D_loss = (D_H_loss + D_Z_loss)/2 \n",
    "            \n",
    "        opt_disc.zero_grad()\n",
    "        d_scaler.scale(D_loss).backward()\n",
    "        d_scaler.step(opt_disc)\n",
    "        d_scaler.update()\n",
    "        \n",
    "        \n",
    "        # train Generators H and Z \n",
    "        with torch.cuda.amp.autocast():\n",
    "            # adversarial loss for both generators\n",
    "            D_H_fake = disc_H(fake_horse)\n",
    "            D_Z_fake = disc_Z(fake_zebra)\n",
    "            loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n",
    "            loss_G_Z = mse(D_Z_fake, torch.ones_like(D_Z_fake))\n",
    "\n",
    "            # cycle loss\n",
    "            cycle_zebra = gen_Z(fake_horse)\n",
    "            cycle_horse = gen_H(fake_zebra)\n",
    "            cycle_zebra_loss = l1(zebra, cycle_zebra)\n",
    "            cycle_horse_loss = l1(horse, cycle_horse)\n",
    "\n",
    "            # identity loss (remove these for efficiency if you set lambda_identity=0)\n",
    "            identity_zebra = gen_Z(zebra)\n",
    "            identity_horse = gen_H(horse)\n",
    "            identity_zebra_loss = l1(zebra, identity_zebra)\n",
    "            identity_horse_loss = l1(horse, identity_horse)\n",
    "\n",
    "            # add all togethor\n",
    "            G_loss = (\n",
    "                loss_G_Z\n",
    "                + loss_G_H\n",
    "                + cycle_zebra_loss * config.LAMBDA_CYCLE\n",
    "                + cycle_horse_loss * config.LAMBDA_CYCLE\n",
    "                + identity_horse_loss * config.LAMBDA_IDENTITY\n",
    "                + identity_zebra_loss * config.LAMBDA_IDENTITY\n",
    "            )\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        g_scaler.scale(G_loss).backward()\n",
    "        g_scaler.step(opt_gen)\n",
    "        g_scaler.update()\n",
    "\n",
    "        if idx % 200 == 0:\n",
    "            save_image(fake_horse*0.5+0.5, str(f\"saved_images/horse_{idx}.png\"))\n",
    "            save_image(fake_zebra*0.5+0.5, str(f\"saved_images/zebra_{idx}.png\"))\n",
    "\n",
    "        loop.set_postfix(H_real=H_reals/(idx+1), H_fake=H_fakes/(idx+1))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    disc_H = Discriminator().to(config.DEVICE)\n",
    "    disc_Z = Discriminator().to(config.DEVICE)\n",
    "    gen_H = Generator().to(config.DEVICE)\n",
    "    gen_Z = Generator().to(config.DEVICE)\n",
    "    \n",
    "    opt_disc = optim.Adam(\n",
    "    \n",
    "        list(disc_H.parameters()) + list(disc_Z.parameters()),\n",
    "        lr = config.LEARNING_RATE,\n",
    "        betas = (0.5, 0.999)\n",
    "    )\n",
    "    opt_gen = optim.Adam(\n",
    "        list(gen_Z.parameters()) + list(gen_H.parameters()),\n",
    "        lr=config.LEARNING_RATE,\n",
    "        betas=(0.5, 0.999),\n",
    "    )\n",
    "    \n",
    "    L1 = nn.L1Loss()\n",
    "    mse = nn.MSELoss()\n",
    "    \n",
    "    if config.LOAD_MODEL:\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_GEN_H, gen_H, opt_gen, config.LEARNING_RATE,\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_GEN_Z, gen_Z, opt_gen, config.LEARNING_RATE,\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_CRITIC_H, disc_H, opt_disc, config.LEARNING_RATE,\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_CRITIC_Z, disc_Z, opt_disc, config.LEARNING_RATE,\n",
    "        )\n",
    "        \n",
    "    root_horse = \"data/horse2zebra/horse2zebra/trainA\"\n",
    "    root_zebra = \"data/horse2zebra/horse2zebra/trainB\"\n",
    "    dataset = HorseZebraDataset(root_zebra,root_horse, config.transforms)\n",
    "    val_dataset = HorseZebraDataset(\"data/horse2zebra/horse2zebra/testB\", \"data/horse2zebra/horse2zebra/testA\", config.transforms)\n",
    "    loader = DataLoader(dataset, batch_size = config.BATCH_SIZE, \n",
    "                       shuffle = True, \n",
    "                       num_workers = config.NUM_WORKERS,\n",
    "                       pin_memory = True)\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size = 1, shuffle = False, pin_memory = True\n",
    "        )\n",
    "    \n",
    "    g_scaler = torch.cuda.amp.GradScaler()\n",
    "    d_scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    for epoch in range(config.NUM_EPOCHS):\n",
    "        train_fn(disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler)\n",
    "        if config.SAVE_MODEL:\n",
    "            save_checkpoint(gen_H, opt_gen, filename=config.CHECKPOINT_GEN_H)\n",
    "            save_checkpoint(gen_Z, opt_gen, filename=config.CHECKPOINT_GEN_Z)\n",
    "            save_checkpoint(disc_H, opt_disc, filename=config.CHECKPOINT_CRITIC_H)\n",
    "            save_checkpoint(disc_Z, opt_disc, filename=config.CHECKPOINT_CRITIC_Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\md. iqbal hossain\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|                                                                                         | 0/1334 [00:00<?, ?it/s]c:\\users\\md. iqbal hossain\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\cuda\\amp\\autocast_mode.py:117: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n",
      "  0%|                                                   | 1/1334 [00:19<7:15:42, 19.61s/it, H_fake=0.515, H_real=0.518]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ec9775ede022>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-5af56829e85b>\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisc_H\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisc_Z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_Z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_H\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_disc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_scaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_scaler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVE_MODEL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0msave_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_H\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHECKPOINT_GEN_H\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-1091b354acee>\u001b[0m in \u001b[0;36mtrain_fn\u001b[1;34m(disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mD_H_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisc_H\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhorse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mD_H_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisc_H\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_horse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mH_reals\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mD_H_real\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\md. iqbal hossain\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-db6677073ff8>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\md. iqbal hossain\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\md. iqbal hossain\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\md. iqbal hossain\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\md. iqbal hossain\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\md. iqbal hossain\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\md. iqbal hossain\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\md. iqbal hossain\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    392\u001b[0m             return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n\u001b[0;32m    393\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                             _pair(0), self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m    396\u001b[0m                         self.padding, self.dilation, self.groups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
